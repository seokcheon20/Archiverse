---
title: Integrity
tags:
  - glossary
  - misc
  - ai
  - resources
date: 2024-10-23
lastmod: 2024-10-23
draft: false
---
Integrity in the academic context can be thought of as multiple qualities of a work that, when put together, establish the argument that people should take you seriously. This is irrespective of the content of the work; it need not contribute anything new or objectively/subjectively valuable to the field in order to have integrity. In large part, works with integrity are:

### Authoritative
The work's conclusion is logically sound as a result of all of the below. The work is self-critical, and if it has logical gaps or counter-arguments, they are mentioned and possibly rebutted. If necessary, it's critical of the question presented.
### Credible
Things that the work holds out as facts are indeed true. If they are drawn from prior work, then the reader needs to be able to examine the reasoning behind those facts, so the work should avoid [[Essays/plagiarism|plagiarism]].
### Rigorous
The methodology used is widely accepted, has an explained basis in prior work, or is laid out in a way that persuades the reader of its veracity. The analysis does not contain any unaddressed logical gaps. The argument is not made in bad faith.

## Further Reading
[[Misc/ai-integrity|Ai lacks integrity]]. It won't take issue with a fallacious question, it is not credible (even if the particular model cites works), and has no true explanation of its methodology.
- Nerdy sidebar: LRM is a misnomer, as "chain-of-reasoning" output is generated at a second step after the actual output. A reinforcement learner selects a reasoning theory from a group based on how reasonable it sounds that the output was achieved from that chain of reasoning, not because the output *did* encode that reasoning. 
---
title: How to Fix the DMCA
tags:
  - copyright
  - legal
  - ai
date: 2025-07-25
lastmod: 2025-07-25
draft: true
---
Sometimes, I feel like the conversation around AI specifically tends to swallow broader issues in copyright law which are just as pressing. The DMCA has been in effect for decades, and content creators and rights holders alike are often unsatisfied with its results. I want to provide a framework for analyzing solutions to this "DMCA problem" that could also be extended to evaluate other debates in online content. I also apply this framework to various potential evolutions of the DMCA notice-and-takedown process and tech infrastructure built atop that system.

Importantly, I think we must consider the systems as a whole; because the effects leading to the problems below are not merely caused by the DMCA itself, but also the implementation of nets and filters such as the Youtube Content ID system.
## Problems
The DMCA as a statute creates several causes of action in copyright, but the provision at issue here is the *quid pro quo*: platforms that observe a notice-and-takedown procedure outlined in the statute receive immunity from copyright infringement claims against user content. Section 230 (a [[Essays/no-ai-fraud-act#00230 Incentive to Kill|frequent]] [[Essays/normative-ai#Detour Section 230 (*again*)|topic]] here) leaves platforms wide open to liability for intellectual property claims, and this portion serves to partially close that gap.
### Statutory
First, copyright holders can send a notification to an online platform that unauthorized copyrighted material appears on their service in some way, to which the platform must remove the content and notify the user responsible that it was removed subject to the DMCA. Platforms must comply with all of the DMCA requirements to be immune from a copyright infringement lawsuit against them. This is immediately subject to abuse in a vacuum, because of the lack of an initial check on infringement. 
- Note that the platform is also not liable to the user for *any* claim arising out of a content removal after becoming aware of a possible infringement. 

The user then has the right to send a counter-notice to the platform and the owner. This right to respond is how the act aims to address the abuse issues of the above. It's ineffective ==because==

After a period of time from receiving a counter-notice, the platform must reinstate the content unless the owner informs them that they have filed a lawsuit against the user.
### Notice facility at scale
### Detour: TAKE IT DOWN ACT

> [!warning] WIP: **Detour: ISPs**
> At present, Cox Communications is in a legal battle where rightsholders are seeking to force DMCA content blocking at the ISP level. Cox's response is that it has fulfilled all its obligations as a mere conduit (one of the types of platforms entitled to DMCA immunity)
## Solutions

## Further Reading
This entry was inspired by a conversation I had with someone much more informed than me on AI law and policy. h/t to the [Sheppard Mullin firm blog](https://www.ailawandpolicy.com/), on which they contribute to current events updates in easily digestible terms.
---
title: Why I wanted to write about AI
tags:
  - seedling
  - essay
  - ai
  - legal
  - copyright
date: 2024-11-02
lastmod: 2025-08-06
draft: false
---
I've seen many news articles and opinion pieces recently that support training generative AI, most particularly LLMs (such as the ChatGPT/GPT-4 family, LLaMa, Bard, Claude, and countless others) on the broader internet, as well as on more traditional copyrighted works. The general sentiment from the industry and some critics is that training should not consider the copyright holders for all of the above. 

<img src="/Attachments/but-he-can.jpg" alt="'I know, but he can' meme, with the RIAA defeating AI art for independent illustrators" style="margin: 0em 5%" loading="lazy">

This is likely because there's a growing sentiment against copyright in general. Copyright can enable centralization of rights when paired with a capitalist economy, which is what we've historically experienced with the advent of copyright repositories like record labels and publishing companies. It's even statutorily enshrined as the "work-for-hire" doctrine. AI has the potential to be an end-run around these massive corporations' rights, which many see as a benefit.

However, this argument forgets that intangible rights are not *yet* so centralized that independent rights-holders have ceased to exist. While AI will indeed affect central rights-holders, it will also harm individual creators and diminish the bargaining power of those that choose to work with central institutions. I see AI as a neutral factor to the disestablishment of copyright. Due to my roots in the indie music and open-source communities, I'd much rather keep their/our/**your** present rights intact.

Unfortunately, because US copyright law is so easily abused, I think the most likely outcome is that publishers/centralized rights holders get their due, and individual creators get the shaft. This isn't a foregone conclusion, and I think some points may be [[Essays/normative-ai#Final thoughts on fair use|more favorable]] to individual artists than publishers, but it still makes me sympathetic to arguments against specific parts of the US's copyright regime as enforced by the courts, such as the DMCA or the statutory language of fair use. We as a voting population have the power to compel our representatives to enact reforms that take the threat of ultimate centralization into account. We can even work to break down what's already here. But I don't think that AI should be the impetus for arguments against the system as a whole.

Finally, remember that perfect is the enemy of good enough. While we're having these discussions about how to regulate GenAI, unregulated use is causing real economic and personal [[Atomic/gen-ai#Causes for concern|harm]] to creators, underrepresented minorities, and consumers as a whole. I am personally in favor of courts reaching substantive issues sooner than later. As with Section 230, Congress works best in a reflective context, where they can proscribe an approach that they don't like rather than prescribe an approach without prior experimentation.
## Further Reading
- [[Atomic/gen-ai|Generative AI, explained]]
- [[Misc/training-copyright|Copyright applied to training]]
- [[Misc/generation-copyright|Copyright applied to output]]
- [[Essays/normative-ai|Why copyright ought to be applied to AI]]
- [[Misc/ai-integrity|Academic Integrity and AI]]
- [[Essays/no-ai-fraud-act|No AI FRAUD Act bill, Section 230, and platforms]]
